{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-13T18:31:03.085405Z",
     "iopub.status.busy": "2024-12-13T18:31:03.084980Z",
     "iopub.status.idle": "2024-12-13T18:31:36.333352Z",
     "shell.execute_reply": "2024-12-13T18:31:36.332506Z",
     "shell.execute_reply.started": "2024-12-13T18:31:03.085368Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.13' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: 'c:/Users/ethan_q0rnnrg/AppData/Local/Microsoft/WindowsApps/python3.9.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T18:31:36.335191Z",
     "iopub.status.busy": "2024-12-13T18:31:36.334838Z",
     "iopub.status.idle": "2024-12-13T18:31:47.006049Z",
     "shell.execute_reply": "2024-12-13T18:31:47.005362Z",
     "shell.execute_reply.started": "2024-12-13T18:31:36.335168Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import classification_report\n",
    "#tensorflow libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import MaxPooling2D, Dense, Dropout,Flatten, Conv2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import TensorBoard,EarlyStopping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T18:31:47.007828Z",
     "iopub.status.busy": "2024-12-13T18:31:47.007195Z",
     "iopub.status.idle": "2024-12-13T18:31:47.103643Z",
     "shell.execute_reply": "2024-12-13T18:31:47.102910Z",
     "shell.execute_reply.started": "2024-12-13T18:31:47.007794Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "Basophil = '/kaggle/input/dataset-bc/Basophil'\n",
    "Eosinophil = '/kaggle/input/dataset-bc/Eosinophil'\n",
    "Lymphocytes = '/kaggle/input/dataset-bc/Lymphocytes'\n",
    "Monocytes = '/kaggle/input/dataset-bc/Monocytes'\n",
    "Neutrophil = '/kaggle/input/dataset-bc/Neutrophil'\n",
    "\n",
    "filepaths = []\n",
    "labels = []\n",
    "\n",
    "dict_list = [Basophil, Eosinophil, Lymphocytes, Monocytes, Neutrophil] # dictionary list cancer cell types\n",
    "\n",
    "for i, j in enumerate(dict_list):\n",
    "    flist = os.listdir(j)\n",
    "    for f in flist:\n",
    "        fpath = os.path.join(j, f)\n",
    "        filepaths.append(fpath)\n",
    "        testx = ['Basophil, Eosinophil, Lymphocytes, Monocytes, Neutrophil']\n",
    "        if 0<=i<=4: labels.append(testx[i])\n",
    "        # if i == 0:\n",
    "        #     labels.append('Basophil')\n",
    "        # elif i == 1:\n",
    "        #     labels.append('Eosinophil')\n",
    "        # elif i == 2:\n",
    "        #     labels.append('Lymphocytes')\n",
    "        # elif i == 3:\n",
    "        #     labels.append('Monocytes')\n",
    "        # elif i == 4:\n",
    "        #     labels.append('Neutrophil')\n",
    "\n",
    "Fseries = pd.Series(filepaths, name=\"filepaths\")\n",
    "Lseries = pd.Series(labels, name=\"labels\")\n",
    "bc_data = pd.concat([Fseries, Lseries], axis=1)\n",
    "bc_df = pd.DataFrame(bc_data)\n",
    "\n",
    "print(bc_df.head())\n",
    "print(bc_df[\"labels\"].value_counts())\n",
    "\n",
    "# Shape of the dataset\n",
    "print(bc_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T18:31:47.106265Z",
     "iopub.status.busy": "2024-12-13T18:31:47.105779Z",
     "iopub.status.idle": "2024-12-13T18:31:47.117068Z",
     "shell.execute_reply": "2024-12-13T18:31:47.116257Z",
     "shell.execute_reply.started": "2024-12-13T18:31:47.106240Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#splitting data\n",
    "train_images, test_images = train_test_split(bc_df, test_size=0.3, random_state=42)\n",
    "train_set, val_set = train_test_split(bc_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T18:31:47.118182Z",
     "iopub.status.busy": "2024-12-13T18:31:47.117980Z",
     "iopub.status.idle": "2024-12-13T18:31:47.123154Z",
     "shell.execute_reply": "2024-12-13T18:31:47.122356Z",
     "shell.execute_reply.started": "2024-12-13T18:31:47.118163Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#shape of splitted data\n",
    "print(train_set.shape)\n",
    "print(test_images.shape)\n",
    "print(val_set.shape)\n",
    "print(train_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T18:31:47.124223Z",
     "iopub.status.busy": "2024-12-13T18:31:47.124026Z",
     "iopub.status.idle": "2024-12-13T18:32:08.483156Z",
     "shell.execute_reply": "2024-12-13T18:32:08.482534Z",
     "shell.execute_reply.started": "2024-12-13T18:31:47.124206Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Generate batches of tensor image data with real-time data augmentation.\n",
    "image_gen = ImageDataGenerator(preprocessing_function= tf.keras.applications.mobilenet_v2.preprocess_input)\n",
    "train = image_gen.flow_from_dataframe(dataframe= train_set,x_col=\"filepaths\",y_col=\"labels\",\n",
    "                                      target_size=(244,244),\n",
    "                                      color_mode='rgb',\n",
    "                                      class_mode=\"categorical\", #used for Sequential Model\n",
    "                                      batch_size=32,\n",
    "                                      shuffle=False            #do not shuffle data\n",
    "                                     )\n",
    "test = image_gen.flow_from_dataframe(dataframe= test_images,x_col=\"filepaths\", y_col=\"labels\",\n",
    "                                     target_size=(244,244),\n",
    "                                     color_mode='rgb',\n",
    "                                     class_mode=\"categorical\",\n",
    "                                     batch_size=32,\n",
    "                                     shuffle= False\n",
    "                                    )\n",
    "val = image_gen.flow_from_dataframe(dataframe= val_set,x_col=\"filepaths\", y_col=\"labels\",\n",
    "                                    target_size=(244,244),\n",
    "                                    color_mode= 'rgb',\n",
    "                                    class_mode=\"categorical\",\n",
    "                                    batch_size=32,\n",
    "                                    shuffle=False\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T18:32:08.484319Z",
     "iopub.status.busy": "2024-12-13T18:32:08.484090Z",
     "iopub.status.idle": "2024-12-13T18:32:08.488593Z",
     "shell.execute_reply": "2024-12-13T18:32:08.487803Z",
     "shell.execute_reply.started": "2024-12-13T18:32:08.484299Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "classes=list(train.class_indices.keys())\n",
    "print (classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T18:32:08.489852Z",
     "iopub.status.busy": "2024-12-13T18:32:08.489563Z",
     "iopub.status.idle": "2024-12-13T18:32:08.502134Z",
     "shell.execute_reply": "2024-12-13T18:32:08.501363Z",
     "shell.execute_reply.started": "2024-12-13T18:32:08.489825Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def bc_images(image_gen):\n",
    "    test_dict = test.class_indices\n",
    "    classes = list(test_dict.keys())\n",
    "    images, labels=next(image_gen) # get a sample batch from the generator \n",
    "    plt.figure(figsize=(20,20))\n",
    "    length = len(labels)\n",
    "    if length<25:\n",
    "        r=length\n",
    "    else:\n",
    "        r=25\n",
    "    for i in range(r):\n",
    "        plt.subplot(5,5,i+1)\n",
    "        image=(images[i]+1)/2 #scale images between 0 and 1\n",
    "        plt.imshow(image)\n",
    "        index=np.argmax(labels[i])\n",
    "        class_name=classes[index]\n",
    "        plt.title(class_name, color=\"green\",fontsize=16)\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T18:32:08.503275Z",
     "iopub.status.busy": "2024-12-13T18:32:08.502998Z",
     "iopub.status.idle": "2024-12-13T18:32:11.721615Z",
     "shell.execute_reply": "2024-12-13T18:32:11.720616Z",
     "shell.execute_reply.started": "2024-12-13T18:32:08.503254Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "bc_images(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T18:32:11.726399Z",
     "iopub.status.busy": "2024-12-13T18:32:11.726132Z",
     "iopub.status.idle": "2024-12-13T18:32:13.540740Z",
     "shell.execute_reply": "2024-12-13T18:32:13.540023Z",
     "shell.execute_reply.started": "2024-12-13T18:32:11.726376Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "IMG_SIZE = (224, 224,3)\n",
    "vgg16_weight_path = '../input/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "base_model = VGG16(\n",
    "    weights=vgg16_weight_path,\n",
    "    include_top=False,\n",
    "    input_shape=IMG_SIZE\n",
    ")\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T18:32:13.542016Z",
     "iopub.status.busy": "2024-12-13T18:32:13.541751Z",
     "iopub.status.idle": "2024-12-13T18:32:13.666552Z",
     "shell.execute_reply": "2024-12-13T18:32:13.665744Z",
     "shell.execute_reply.started": "2024-12-13T18:32:13.541994Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "\n",
    "NUM_CLASSES = 5\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(NUM_CLASSES, activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=RMSprop(learning_rate=1e-4),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "base_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T18:32:13.667868Z",
     "iopub.status.busy": "2024-12-13T18:32:13.667613Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#start = time.time()\n",
    "History = model.fit(\n",
    "    train,\n",
    "    epochs=10,\n",
    "    validation_data=val,  # pass the validation generator here\n",
    "    verbose=1\n",
    ")\n",
    "#print(\"Total time: \", time.time() - start, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "acc = History.history[\"accuracy\"] # report of model\n",
    "val_acc = History.history[\"val_accuracy\"] # history of validation data\n",
    "\n",
    "loss = History.history[\"loss\"]        # Training loss\n",
    "val_loss = History.history[\"val_loss\"] # validation loss\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.subplot(2,1,1) # 2 rows and 1 columns\n",
    "#plotting respective accuracy\n",
    "plt.plot(acc,label=\"Training Accuracy\")\n",
    "plt.plot(val_acc, label=\"Validation Acccuracy\")\n",
    "\n",
    "plt.legend()\n",
    "plt.ylabel(\"Accuracy\", fontsize=12)\n",
    "plt.title(\"Training and Validation Accuracy\", fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.subplot(2,1,1)\n",
    "\n",
    "plt.plot(loss, label=\"Training Loss\")      #Training loss\n",
    "plt.plot(val_loss, label=\"Validation Loss\") # Validation Loss\n",
    "\n",
    "plt.legend()\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.ylabel(\"Loss\", fontsize=12)\n",
    "plt.title(\"Training and Validation Losses\", fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.evaluate(test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pred = model.predict(test)\n",
    "pred = np.argmax(pred, axis=1) #pick class with highest  probability\n",
    "\n",
    "labels = (train.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "pred2 = [labels[k] for k in pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "\n",
    "y_test = test_images.labels # set y_test to the expected output\n",
    "print(classification_report(y_test, pred2))\n",
    "print(\"Accuracy of the Model:\",accuracy_score(y_test, pred2)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "plt.figure(figsize = (10,5))\n",
    "cm = confusion_matrix(y_test, pred2)\n",
    "sns.heatmap(cm, annot=True, fmt = 'g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES=5 # class number\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "#vgg = VGG19(weights=\"../input/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\",include_top = False,input_shape=(224,244,3))\n",
    "vgg = VGG19(weights=\"../input/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\",\n",
    "            include_top = False,input_shape=(224,224,3)\n",
    "           )\n",
    "for layer in vgg.layers:\n",
    "    layer.trainable = False\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Flatten,Dense\n",
    "model = Sequential()\n",
    "model.add(vgg)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(NUM_CLASSES, activation=\"softmax\"))\n",
    "#model.add(Dense(2,activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience = 2, verbose=1,factor=0.3, min_lr=0.000001)\n",
    "#fitting model\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "History = model.fit(train,validation_data= val, epochs=10,verbose=1)\n",
    "print(\"Total time: \", time.time() - start, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "acc = History.history[\"accuracy\"] # report of model\n",
    "val_acc = History.history[\"val_accuracy\"] # history of validation data\n",
    "\n",
    "loss = History.history[\"loss\"]        # Training loss\n",
    "val_loss = History.history[\"val_loss\"] # validation loss\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.subplot(2,1,1) # 2 rows and 1 columns\n",
    "#plotting respective accuracy\n",
    "plt.plot(acc,label=\"Training Accuracy\")\n",
    "plt.plot(val_acc, label=\"Validation Acccuracy\")\n",
    "\n",
    "plt.legend()\n",
    "plt.ylabel(\"Accuracy\", fontsize=12)\n",
    "plt.title(\"Training and Validation Accuracy\", fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.subplot(2,1,1)\n",
    " \n",
    "plt.plot(loss, label=\"Training Loss\")      #Training loss\n",
    "plt.plot(val_loss, label=\"Validation Loss\") # Validation Loss\n",
    "\n",
    "plt.legend()\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.ylabel(\"Loss\", fontsize=12)\n",
    "plt.title(\"Training and Validation Losses\", fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.evaluate(test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pred = model.predict(test)\n",
    "pred = np.argmax(pred, axis=1) #pick class with highest  probability\n",
    "\n",
    "labels = (train.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "pred2 = [labels[k] for k in pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "\n",
    "y_test = test_images.labels # set y_test to the expected output\n",
    "print(classification_report(y_test, pred2))\n",
    "print(\"Accuracy of the Model:\",accuracy_score(y_test, pred2)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.save('blood_cancer_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6302,
     "sourceId": 9896,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6303,
     "sourceId": 9897,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4090690,
     "sourceId": 7097352,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30588,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
